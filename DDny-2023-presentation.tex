\documentclass[10pt, 169]{beamer}

\usepackage{polyglossia}
\usepackage{csquotes}
\usepackage{bm}
\usepackage{datetime}
\usepackage{fontspec}
\usepackage{microtype}
\usepackage{color}
\usepackage{url}
\usepackage{pgfplots}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{subcaption}
\usepackage[backend=biber,style=iso-authoryear,sortlocale=en_US,autolang=other,bibencoding=UTF8]{biblatex}
\usepackage{booktabs}
\usepackage{graphics}
\usepackage{pifont}
\usepackage{ulem}
\usepackage{tikz}

\usepgfplotslibrary{fillbetween}
\usetikzlibrary{arrows,automata,shapes,calc, patterns, backgrounds}

\addbibresource{zotero.bib}

\setdefaultlanguage{english}
\setmainfont{TeX Gyre Termes}
\usetheme{Boadilla}
\usecolortheme{crane}
\setbeamertemplate{title page}[default][rounded=true,shadow=false]
\setbeamertemplate{section in toc}[ball unnumbered]
\setbeamertemplate{bibliography item}{}

\hypersetup{
	pdfencoding=auto,
	unicode=true,
	citecolor=green,
	filecolor=blue,
	linkcolor=red,
	urlcolor=blue
}

\makeatletter
\newcommand*{\currentSection}{\@currentlabelname}
\makeatother

\newcommand{\mathmat}{\ensuremath{\mathbf}}

\title[DDny 2023]
{
	Which Graph Properties Affect GNN Performance for a Given Downstream Task?
}

\newdate{presentation}{10}{11}{2023}
\date[November 2023]{Doktorandské dny KM FJFI, \displaydate{presentation}}

\author[Procházka et al.]{
	Pavel Procházka\inst{1} \and
	Michal Mareš\inst{1,2} \and
	\underline{Marek Dědič}\inst{1,2}
}
\institute[Cisco \& CTU]{
	\inst{1}Cisco Systems, Inc. \and
	\inst{2}Czech Technical University in Prague
}

% Title card
\AtBeginSection[]{
	\begin{frame}
	\vfill
	\centering
	\begin{beamercolorbox}[sep = 8pt,center,shadow = true,rounded = true]{title}
		\usebeamerfont{title}\insertsectionhead\par%
	\end{beamercolorbox}
	\vfill
\end{frame}
}

\begin{document}

\begin{frame}
	\titlepage
\end{frame}


\begin{frame}
	\frametitle{Motivation -- Representation by Graph}
	{\scalebox{0.45}{\input{images/motivation}}} 
\end{frame}

\begin{frame}
	\frametitle{Graph Composition -- Naive Approach}
	{\scalebox{0.45}{\input{images/approach}}} 
\end{frame}

\begin{frame}
	\frametitle{Graph Composition -- Proposed Approach}
	{\scalebox{0.8}{\input{images/proposed_approach}}}
\end{frame}

\begin{frame}
	\frametitle{Hyper-Parameter Tuning}
	{\scalebox{0.8}{\input{images/hyperpar_description}}}
\end{frame}



\begin{frame}
	\frametitle{Dataset Construction}
	\scalebox{0.45} {\input{images/dataset_description}}
\end{frame}

\begin{frame}
	\frametitle{Experiment Setup -- Dataset Construction}
	\scalebox{0.45}
	{\input{images/experiment_design}}
	%{\input{images/datasets.tex}}
\end{frame}

\begin{frame}
	\frametitle{Meta-Model Generalisation Capability -- Experiment Setup}	 
	\begin{enumerate}
		\item Random split of the 139 tasks to train and test sets with sizes 93 and 46
		\item Label given by the best performance of each task over all hyper-parameters
		\item Random forest regression model trained on graph properties to fit true label
		\item Measuring RMSE and Spearman correlation between prediction and true label
		\item Performance on test set indicating generalization ability
		\item Relating	graph properties in terms of feature interpretation of the model
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Meta-Model Generalisation Capability -- Results}
	\scalebox{0.9} {\includegraphics{images/gnn_random_split_prec_logloss.pdf}}
\end{frame}

\begin{frame}
	\frametitle{Interpretation -- Impact on Log Loss}
	\scalebox{1} {\includegraphics[width=0.9\linewidth]{images/shap_logloss.pdf}}
\end{frame}

\begin{frame}
	\frametitle{Hyper-Parameter Tuning Experiment Setup}
	\input{images/hyperpar_setup}
\end{frame}

\begin{frame}
	\frametitle{Hyper-Parameter Tuning Results}
	\scalebox{1} {\includegraphics[width=0.7\linewidth]{images/hyperpar_tuning_small_single.pdf}}
\end{frame}

\begin{frame}
	\frametitle{Hyper-Parameter Tuning Results}
	\scalebox{1} {\includegraphics[width=0.9\linewidth]{images/hyperpar_tuning_small1.pdf}}
\end{frame}

\begin{frame}
	\frametitle{Hyper-Parameter Tuning Results}
	\scalebox{1} {\includegraphics[width=0.9\linewidth]{images/hyperpar_tuning_small2.pdf}}
\end{frame}

\begin{frame}
	\frametitle{Hyper-Parameter Tuning Results}
	\scalebox{1} {\includegraphics[width=0.9\linewidth]{images/hyperpar_tuning_small3.pdf}}
\end{frame}

\begin{frame}
	\frametitle{Conclusions}
	\begin{itemize}
		\item Proposed a method for identification of important graph
dataset properties using meta-model
		\item Hyper-parameter tuning method
based on the meta-model
		\item Experimental validation of meta-model generalization capability
		\item Evaluated importance of graph properties and their impact on GNN performance
		\item Very promissing results of hyper-parameter search method
		\item More details can be found in the paper: \cite{prochazka_which_2023}
	\end{itemize}
\end{frame}

\begin{frame}{Bibliography}
	\printbibliography
\end{frame}

\begin{frame}
	\titlepage
\end{frame}

\end{document}
